\chapter{Discussion}
As already seen in the state of the art section, there have also been improvements since the publication of SciBERT, but even the more recent models are definitely not yet performing perfectly, which is probably not a realistic expectation, but still show potential for improvement in terms of their scores in the various NLP tasks. If one briefly deviates from the evaluation by means of score at this point and takes a look at the efficiency and necessary resources, an even greater deficit becomes apparent than the actual performance in the NLP tasks. In particular, these high demands on the hardware used generally makes it difficult to conduct research in this area. Here, this was solved using google-colab, which in turn has its own weaknesses, especially due to restrictions that limit longer-lasting training times. 

But now we are getting back to the actual scores and here especially S2ORC-BERT showed the impact of a larger corpus can have. In particular, the comparison between OAG-BERT and S2ORC shows that a more complex model is not always necessary to perform better on NLP tasks. However, OAG-BERT allows us to incorporate more information into the underlying BERT model, which turns out to be useful for tasks that can benefit from such knowledge. Here it can be summarized that there is no one perfect model but one has to decide depending on the area of application. Nevertheless, it can be said that there are advancements to models that could replace the previous one. For example S2ORC-BERT, which can generally be used instead of SciBERT. However, it must be mentioned that S2ORC-BERT is almost always better than SciBERT, even though S2ORC-BERT covers a much wider range of domains and is not as precisely tuned as SciBERT to the task relevant domains. While the difference in F1 score is usually small, one might expect S2ORC-BERT to perform similarly well in other domains, whereas SciBERT might need more data and longer finetuning to come close to S2ORC-BERT performance.  


For the replication it can be summarized that especially the documentation and the examples for many Julia libraries used here are insufficient. Missing information may still be acceptable, but wrong or more precisely non-functioning examples will quickly lead you astray. Especially if currently working and non working examples are not separated and are even available in the same folder as examples. Although tests often offer a working example, in order to explicitly consider only these, it must be known that the normal documentation is not always reliable. Furthermore, the problem with the available hardware became apparent. Depending on the individual equipment, it is extremely difficult to investigate models of this size effectively. 
\subsection{Further development}