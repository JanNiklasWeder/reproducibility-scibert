\chapter{Experiments}
kurze einführung in die test fälle mit einer erklärung, was f1 scores sind\\
Alles NLP Aufgaben bei denen Bert "überraschend" gut abschneided\\
Jetzt mit der erweiterung zu scibert erneut betrachtet\\
Einföuss des vocabulars und des corpus genau gegenübergestellt\\

all got dropout of 0.1
loss cross entropy
optemizer adam
finetuning for 2 to 5 epochs 
\section{NER}
Pretrained model -> linear classification layer with softmax output
\section{PICO}
\section{CLS}
\section{REL}
\section{DEP}
dependency  tag and arc embedding of size 100 and biaffine matrix attention 
\section{Finetuning}
\section{Frozen embeddings}
