\chapter{Experiments}
kurze einführung in die test fälle mit einer erklärung, was f1 scores sind\\
Alles NLP Aufgaben bei denen Bert "überraschend" gut abschneided\\
Jetzt mit der erweiterung zu scibert erneut betrachtet\\
Einföuss des vocabulars und des corpus genau gegenübergestellt\\

all got dropout of 0.1
loss cross entropy
optemizer adam
finetuning for 2 to 5 epochs 
\section{NER}
Pretrained model -> linear classification layer with softmax output
\section{PICO}
\section{CLS}
\section{REL}
\section{DEP}
dependency  tag and arc embedding of size 100 and biaffine matrix attention 
\section{Finetuning}
\section{Frozen embeddings}

\section{Influences of different platforms}
This section will take a short look at the usability of different hardware platforms for the creation of transformer models and in the training or testing of those. More precisely we will compare the google-colab environment with an Nvidia GPU and an AMD GPU. Due to the randomness of the allocation of hardware on the google-colab site, I cannot further define the GPU that was used on this platform. The Nvidia GPU that was used is a GeForce 940MX with approximate 2GB VRAM, the AMD GPU on the other side was an RX580 with approximate 8GB of VRAM.\\
At this point, I will shortly describe how far the ROCM stack of AMD is usable because surprisingly I was able to define the model and make predictions with it in a randomized instance. Sadly due to the instability in the ROCM stack, the Linux kernel wasn't capable of using the GPU anymore after an update which probably broke the intern dependencies on which the kernel and the ROCM driver relay and therefore the Video output of the computer was not usable anymore. Even though this shows that in fact, an AMD GPU is capable of running the Transformer package and at least load a defined model. This fact in itself is surprising since AMD itself describes the support status of the RX580 as it "may or may not work" and Julia describes the support of AMD GPUs as level 3 which corresponds to the lowest level of support. (verweis zu der aussage)[belege und verweis zu ROCM]\\
Still, I would discourage anyone from installing the ROCM stack on any productive system since it is still way too unstable and would recommend experimenting only in some form of a virtualized environment. \\
Due to the failure with the ROCM stack, the following part will only consider the MX940 and the google-colab environment.
