\chapter{Introduction}
\color{ForestGreen}
\begin{itemize}
	\item Als pretrained model hängt bert stark von dem korpus ab
	\item Genauso ist das vocabular sehr wichtig
	\item Andere arbeiten zeigten den einfluss eines erweiterten trainings/besser passenden korpus? referenz suchen
	\item $\Longrightarrow$ Roberta zum Beispiel zeigte, dass allein weiteres training die ergebnisse verbessern kann
	\item Wissenschaftlöiche texte unterschieden sich allgemein sehr stark von "normalen"
	\item $\Rightarrow$ Somit ist ein auf ähnliche weise trainiertes modell als bessere grundlagen für NLP aufgaben im wissenschaftlichen bereich sinnvoll
	\item Gab es in dieser form noch nicht
	\item $\Rightarrow$ besitzt daher potential (annahme das BERT gut sei)
	\item insbesondere als grundbaustein für unterschiedlichste aufgaben im !!! wiss. bereich
	\item Allgemein stellt sich das Problem von Datensätzen insbesondere da diese annotiert werden müssen (im wiss. bereich teuer da hochqualifizierte experten notwendig sind)
\end{itemize}
\color{black}